# Emmit-Tiny: Scaled-down model for single-GPU debugging & validation
# ~25M parameters (active), fast iteration

model:
  name: "emmit-tiny"
  hidden_size: 512
  num_layers: 8
  num_attention_heads: 8
  num_key_value_heads: 2        # GQA: 4x compression
  ffn_hidden_size: 1376         # ~2.7x hidden_size (SwiGLU)
  max_position_embeddings: 4096
  rope_theta: 10000.0
  vocab_size: 32000

  # MoE
  num_experts: 4
  num_experts_per_token: 2      # Top-2 routing
  expert_capacity_factor: 1.25
  router_aux_loss_coef: 0.01
  router_z_loss_coef: 0.001

  # Vision (disabled for tiny)
  vision_enabled: false
  vision_hidden_size: 512
  vision_num_layers: 6
  image_size: 336
  patch_size: 14

  # Regularization
  dropout: 0.0
  attention_dropout: 0.0

training:
  batch_size: 4
  gradient_accumulation_steps: 4
  max_steps: 50
  learning_rate: 1.0e-3
  warmup_steps: 10
  mixed_precision: "no"
  gradient_checkpointing: false
  logging_steps: 5
  eval_steps: 100
  save_steps: 50
  max_seq_len: 256
  max_checkpoints: 3

  # Data
  pack_sequences: true
